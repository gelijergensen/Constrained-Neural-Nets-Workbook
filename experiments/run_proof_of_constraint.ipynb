{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory to the root so that relative path loads work correctly\n",
    "import os\n",
    "\n",
    "try:\n",
    "    os.chdir(os.path.join(os.getcwd(), \"..\"))\n",
    "    print(os.getcwd())\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from experiments.A_proof_of_constraint.experiment_definition import dictionary_product\n",
    "from experiments.A_proof_of_constraint.main import run_experiment\n",
    "from experiments.A_proof_of_constraint.reductions import Huber_Reduction, Lp_Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving utilities\n",
    "def get_savefile():\n",
    "    base_name = \"proof-of-constraint\"\n",
    "    time_string = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    savefile = f\"{base_name}_{time_string}.pth\"\n",
    "    return savefile\n",
    "\n",
    "\n",
    "def save_out(\n",
    "    summary, savefile, directory=\"/global/u1/g/gelijerg/Projects/pyinsulate/results\"\n",
    "):\n",
    "    full_file = f\"{directory}/{savefile}\"\n",
    "    print(f\"Saving to file {full_file}\")\n",
    "    torch.save(summary, full_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_configuration = {\n",
    "    \"training_parameterizations\": {\n",
    "        \"amplitudes\": [1.0],\n",
    "        \"frequencies\": [1.0],\n",
    "        \"phases\": [0.0],\n",
    "        \"num_points\": 500,\n",
    "        \"sampling\": \"uniform\",\n",
    "    },\n",
    "    \"testing_parameterizations\": {\n",
    "        \"amplitudes\": [1.0],\n",
    "        \"frequencies\": [1.0],\n",
    "        \"phases\": [0.0],\n",
    "        \"num_points\": 500,\n",
    "        \"sampling\": \"uniform\",\n",
    "    },\n",
    "    \"batch_size\": 100,\n",
    "    \"model_size\": [20, 20, 20],\n",
    "    \"method\": \"constrained\",\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"ground_approximation\": None,\n",
    "    \"reduction\": Huber_Reduction(6),\n",
    "    \"model_act\": nn.Tanh(),\n",
    "}\n",
    "\n",
    "configuration_revisions = list(\n",
    "    dictionary_product(\n",
    "        **{\n",
    "            #             \"method\": [\"unconstrained\", \"soft-constrained\", \"reduction\", \"approximate\"],\n",
    "            \"method\": [\"unconstrained\"]\n",
    "        }\n",
    "    )\n",
    ")\n",
    "num_epochs = 400\n",
    "save_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiment\n",
    "all_savefiles = list()\n",
    "final_checkpoints = list()\n",
    "for revision in configuration_revisions:\n",
    "    configuration = base_configuration.copy()\n",
    "    configuration.update(revision)\n",
    "\n",
    "    savefile = get_savefile()\n",
    "    all_savefiles.append(savefile)\n",
    "    print(f\"Running proof of constraint with savefile {savefile}\")\n",
    "    checkpoint_save_file_base = os.path.splitext(savefile)[0]\n",
    "    final_checkpoints.append(f\"{checkpoint_save_file_base}_{num_epochs:05d}.pth\")\n",
    "    final_result = run_experiment(\n",
    "        num_epochs,\n",
    "        log=print,\n",
    "        save_directory=\"results/checkpoints\",\n",
    "        save_file=checkpoint_save_file_base,\n",
    "        save_interval=save_interval,\n",
    "        **configuration,\n",
    "    )\n",
    "    print(f\"Completed run with savefile {savefile}\")\n",
    "    # Save out\n",
    "    configuration, (trainer, train_evaluator, test_evaluator), (\n",
    "        training_monitor,\n",
    "        evaluation_train_monitor,\n",
    "        evaluation_test_monitor,\n",
    "    ) = final_result\n",
    "\n",
    "    save_out(\n",
    "        {\n",
    "            \"configuration\": configuration,\n",
    "            \"training_monitor\": training_monitor,\n",
    "            \"evaluation_train_monitor\": evaluation_train_monitor,\n",
    "            \"evaluation_test_monitor\": evaluation_test_monitor,\n",
    "        },\n",
    "        savefile=savefile,\n",
    "    )\n",
    "print(\"\")\n",
    "print(f\"Files were saved to {all_savefiles}\")\n",
    "print(f\"Checkpoints were saved to {final_checkpoints}\")\n",
    "print(f\"Corresponding revisions {configuration_revisions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done!\")"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python [conda env:.conda-torch-gpu]",
   "language": "python",
   "name": "conda-env-.conda-torch-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
