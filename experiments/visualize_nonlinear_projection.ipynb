{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory to the root so that relative path loads work correctly\n",
    "import os\n",
    "\n",
    "try:\n",
    "    os.chdir(os.path.join(os.getcwd(), \"..\"))\n",
    "    print(os.getcwd())\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from experiments.C_nonlinear_projection.main import build_model_and_optimizer, get_data\n",
    "from experiments.C_nonlinear_projection.visualize import (  # plot_model_predictions,\n",
    "    plot_epoch_wise,\n",
    "    plot_epoch_wise_distribution,\n",
    "    plot_model_predictions,\n",
    "    plot_time,\n",
    "    retrieve_object,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_name_to_filename(model_name):\n",
    "    filename = model_name.replace(\" \", \"-\").lower()\n",
    "    filename = (\n",
    "        filename.replace(\"(\", \"\").replace(\")\", \"\").replace(\":\", \"\").replace(\",\", \"\")\n",
    "    )\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(checkpoint):\n",
    "    config = checkpoint[\"configuration\"]\n",
    "    weight = config[\"regularization_weight\"]\n",
    "    weight_string = (\n",
    "        \"Unconstrained\" if weight == 0.0 else f\"Soft Constrained ({weight:g})\"\n",
    "    )\n",
    "    #     model_act = config[\"model_act\"]\n",
    "    epoch = checkpoint[\"epoch\"]\n",
    "    return f\"{weight_string} Epoch {epoch}\"\n",
    "\n",
    "\n",
    "def get_group_name(checkpoint):\n",
    "    config = checkpoint[\"configuration\"]\n",
    "    weight = config[\"regularization_weight\"]\n",
    "    weight_string = (\n",
    "        \"Unconstrained\" if weight == 0.0 else f\"Soft Constrained ({weight:g})\"\n",
    "    )\n",
    "    return weight_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_special_model_name(checkpoint, filename):\n",
    "    return get_model_name(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files to load\n",
    "experiment_name = \"C_nonlinear_projection\"\n",
    "save_directory = f\"/global/u1/g/gelijerg/Projects/pyinsulate/results/{experiment_name}/\"\n",
    "load_directory = os.path.expandvars(f\"$SCRATCH/results/checkpoints/{experiment_name}\")\n",
    "checkpoint_patterns = [\"nonlinear-projection_2019-08-16-12-06-02_000?0.pth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "files = list()\n",
    "for pattern in checkpoint_patterns:\n",
    "    files.extend(glob.glob(f\"{load_directory}/{pattern}\"))\n",
    "files.sort()\n",
    "print(files)\n",
    "checkpoints = [torch.load(f, map_location=torch.device(\"cpu\")) for f in files]\n",
    "# model_names = [get_model_name(checkpoint) for checkpoint in checkpoints]\n",
    "model_names = [\n",
    "    get_special_model_name(checkpoint, filename)\n",
    "    for checkpoint, filename in zip(checkpoints, files)\n",
    "]\n",
    "# Make sure directory to save exists\n",
    "os.makedirs(save_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some plotting\n",
    "max_epoch = max([checkpoint[\"epoch\"] for checkpoint in checkpoints])\n",
    "final_checkpoints = [\n",
    "    (checkpoint, model_name)\n",
    "    for (checkpoint, model_name) in zip(checkpoints, model_names)\n",
    "    if checkpoint[\"epoch\"] == max_epoch\n",
    "]\n",
    "\n",
    "tasks = [(\"Final Models\", final_checkpoints)]\n",
    "\n",
    "checkpoint_groups = dict()\n",
    "for f, checkpoint, model_name in zip(files, checkpoints, model_names):\n",
    "    key = os.path.basename(f[: f.rfind(\"_\")])\n",
    "    if key not in checkpoint_groups:\n",
    "        checkpoint_groups[key] = list()\n",
    "    checkpoint_groups[key].append((checkpoint, model_name))\n",
    "for group_key, checkpoint_name_pairs in checkpoint_groups.items():\n",
    "    name = get_group_name(checkpoint_name_pairs[0][0])\n",
    "    tasks.append((name, checkpoint_name_pairs))\n",
    "\n",
    "for task_name, task in tasks:\n",
    "    print(task_name)\n",
    "    if len(task) == 0:\n",
    "        print(f\"Nothing for task {task_name}\")\n",
    "        continue\n",
    "    task_checkpoints = [x[0] for x in task]\n",
    "    task_model_names = [x[1] for x in task]\n",
    "    task_monitors = [checkpoint[\"monitors\"] for checkpoint in task_checkpoints]\n",
    "    time_keys = set()\n",
    "    for monitors in task_monitors:\n",
    "        time_keys.update([key for key in monitors[0].timing_keys])\n",
    "    time_keys = list(time_keys)\n",
    "    task_filename = convert_name_to_filename(task_name)\n",
    "\n",
    "    if \"final\" in task_filename:\n",
    "        # TRAINING\n",
    "        fig = plot_time(\n",
    "            [monitors[0] for monitors in task_monitors],\n",
    "            task_model_names,\n",
    "            f\"{task_filename}_compute-time\",\n",
    "            time_keys=time_keys,\n",
    "            log=True,\n",
    "            directory=save_directory,\n",
    "        )\n",
    "        fig = plot_epoch_wise(\n",
    "            [monitors[0] for monitors in task_monitors],\n",
    "            task_model_names,\n",
    "            [retrieve_object(monitors[0], \"total_loss\") for monitors in task_monitors],\n",
    "            f\"{task_filename}_training-total-loss\",\n",
    "            title=\"Training Total Loss\",\n",
    "            ylabel=\"Average loss\",\n",
    "            log=True,\n",
    "            directory=save_directory,\n",
    "        )\n",
    "        fig = plot_epoch_wise(\n",
    "            [monitors[0] for monitors in task_monitors],\n",
    "            task_model_names,\n",
    "            [retrieve_object(monitors[0], \"mean_loss\") for monitors in task_monitors],\n",
    "            f\"{task_filename}_training-loss\",\n",
    "            title=\"Training Data Loss\",\n",
    "            ylabel=\"Average loss\",\n",
    "            log=True,\n",
    "            directory=save_directory,\n",
    "        )\n",
    "        fig = plot_epoch_wise(\n",
    "            [monitors[0] for monitors in task_monitors],\n",
    "            task_model_names,\n",
    "            [\n",
    "                retrieve_object(monitors[0], \"constraints_error\")\n",
    "                for monitors in task_monitors\n",
    "            ],\n",
    "            f\"{task_filename}_training-constraints-error\",\n",
    "            title=\"Training Constraint Error\",\n",
    "            ylabel=\"Average constraint error\",\n",
    "            log=True,\n",
    "            directory=save_directory,\n",
    "        )\n",
    "        fig = plot_epoch_wise_distribution(\n",
    "            [monitors[0] for monitors in task_monitors],\n",
    "            task_model_names,\n",
    "            [\n",
    "                retrieve_object(monitors[0], \"constraints\", absolute_value=False)\n",
    "                for monitors in task_monitors\n",
    "            ],\n",
    "            f\"{task_filename}_training-constraint-distribution\",\n",
    "            title=\"Training Distribution of Constraint Residual\",\n",
    "            ylabel=\"Constraint value\",\n",
    "            log=False,\n",
    "            directory=save_directory,\n",
    "        )\n",
    "        fig = plot_epoch_wise_distribution(\n",
    "            [monitors[0] for monitors in task_monitors],\n",
    "            task_model_names,\n",
    "            [\n",
    "                retrieve_object(monitors[0], \"constraints\", absolute_value=True)\n",
    "                for monitors in task_monitors\n",
    "            ],\n",
    "            f\"{task_filename}_training-constraint-distribution-magnitude\",\n",
    "            title=\"Training Distribution of Magnitude of Constraint Residual\",\n",
    "            ylabel=\"Magnitude of constraint value\",\n",
    "            log=True,\n",
    "            directory=save_directory,\n",
    "        )\n",
    "\n",
    "        # Inference\n",
    "        monitors_to_plot = list()\n",
    "        names_to_plot = list()\n",
    "        data_to_plot = list()\n",
    "        colors = list()\n",
    "        line_styles = list()\n",
    "        for i, (monitors, name) in enumerate(zip(task_monitors, task_model_names)):\n",
    "            monitors_to_plot.extend([monitors[2], monitors[2]])\n",
    "            names_to_plot.extend([f\"{name} (Unprojected)\", f\"{name} (Projected)\"])\n",
    "            data_to_plot.extend(\n",
    "                [\n",
    "                    retrieve_object(monitors[2], \"mean_loss\", original=True),\n",
    "                    retrieve_object(monitors[2], \"mean_loss\", final=True),\n",
    "                ]\n",
    "            )\n",
    "            colors.extend([i, i])\n",
    "            line_styles.extend([\":\", \"--\"])\n",
    "        fig = plot_epoch_wise(\n",
    "            monitors_to_plot,\n",
    "            names_to_plot,\n",
    "            data_to_plot,\n",
    "            f\"{task_filename}_testing-loss\",\n",
    "            colors=colors,\n",
    "            line_styles=line_styles,\n",
    "            title=\"Inference Data Loss\",\n",
    "            ylabel=\"Average loss\",\n",
    "            log=True,\n",
    "            directory=save_directory,\n",
    "        )\n",
    "\n",
    "        monitors_to_plot = list()\n",
    "        names_to_plot = list()\n",
    "        data_to_plot = list()\n",
    "        colors = list()\n",
    "        line_styles = list()\n",
    "        for i, (monitors, name) in enumerate(zip(task_monitors, task_model_names)):\n",
    "            monitors_to_plot.extend([monitors[2], monitors[2]])\n",
    "            names_to_plot.extend([f\"{name} (Unprojected)\", f\"{name} (Projected)\"])\n",
    "            data_to_plot.extend(\n",
    "                [\n",
    "                    retrieve_object(monitors[2], \"constraints_error\", original=True),\n",
    "                    retrieve_object(monitors[2], \"constraints_error\", final=True),\n",
    "                ]\n",
    "            )\n",
    "            colors.extend([i, i])\n",
    "            line_styles.extend([\":\", \"--\"])\n",
    "        fig = plot_epoch_wise(\n",
    "            monitors_to_plot,\n",
    "            names_to_plot,\n",
    "            data_to_plot,\n",
    "            f\"{task_filename}_testing-constraints-error\",\n",
    "            colors=colors,\n",
    "            line_styles=line_styles,\n",
    "            title=\"Inference Constraint Error\",\n",
    "            ylabel=\"Average constraint error\",\n",
    "            log=True,\n",
    "            directory=save_directory,\n",
    "        )\n",
    "        # Maybe put the constraint distributions here, but I think it might be too much\n",
    "        inputs = None\n",
    "        outputs = None\n",
    "        prediction_sets = list()\n",
    "        names_to_plots = list()\n",
    "        colors = list()\n",
    "        line_styles = list()\n",
    "        for i, (monitors, name) in enumerate(zip(task_monitors, task_model_names)):\n",
    "            # Assumption: all models have the same test set\n",
    "            if inputs is None:\n",
    "                inputs = monitors[2].inputs\n",
    "            if outputs is None:\n",
    "                outputs = monitors[2].outputs\n",
    "            prediction_sets.extend(\n",
    "                [monitors[2].original_out[-1], monitors[2].final_out[-1]]\n",
    "            )\n",
    "            names_to_plot.extend([f\"{name} (Unprojected)\", f\"{name} (Projected)\"])\n",
    "            colors.extend([i, i])\n",
    "            line_styles.extend([\":\", \"--\"])\n",
    "        fig = plot_model_predictions(\n",
    "            inputs,\n",
    "            outputs,\n",
    "            prediction_sets,\n",
    "            names_to_plot,\n",
    "            f\"{task_filename}_predictions\",\n",
    "            colors=colors,\n",
    "            line_styles=line_styles,\n",
    "            title=\"Model Predictions\",\n",
    "            directory=save_directory,\n",
    "        )\n",
    "\n",
    "        # Model-wise\n",
    "        for monitors, model_name in zip(task_monitors, task_model_names):\n",
    "            model_filename = convert_name_to_filename(model_name)\n",
    "\n",
    "            fig = plot_epoch_wise_distribution(\n",
    "                [monitors[0]],\n",
    "                [model_name],\n",
    "                [retrieve_object(monitors[0], \"model_parameters\", gradients=False)],\n",
    "                f\"{task_filename}_{model_filename}_parameter-distribution\",\n",
    "                title=f\"Distribution of Parameter Values\",\n",
    "                ylabel=\"Parameter values\",\n",
    "                log=False,\n",
    "                directory=save_directory,\n",
    "            )\n",
    "            fig = plot_epoch_wise_distribution(\n",
    "                [monitors[0]],\n",
    "                [model_name],\n",
    "                [retrieve_object(monitors[0], \"model_parameters\", gradients=True)],\n",
    "                f\"{task_filename}_{model_filename}_gradient-distribution\",\n",
    "                title=f\"Distribution of Parameter Gradients\",\n",
    "                ylabel=\"Parameter gradients\",\n",
    "                log=False,\n",
    "                directory=save_directory,\n",
    "            )\n",
    "            fig = plot_epoch_wise_distribution(\n",
    "                [monitors[2]],\n",
    "                [model_name],\n",
    "                [retrieve_object(monitors[2], \"model_parameters\", differences=True)],\n",
    "                f\"{task_filename}_{model_filename}_parameter-differences\",\n",
    "                title=f\"Distribution of Parameter Differences During Inference\",\n",
    "                ylabel=\"Parameter differences\",\n",
    "                log=False,\n",
    "                directory=save_directory,\n",
    "            )\n",
    "            # Plot process of projection\n",
    "            inputs = monitors[2].inputs\n",
    "            outputs = monitors[2].outputs\n",
    "            prediction_sets = [monitors[2].original_out[-1]]\n",
    "            names_to_plot = [\"Unprojected\"]\n",
    "            line_styles = [\":\"]\n",
    "            for i in range(len(monitors[2].all_out[-1])):\n",
    "                prediction_sets.append(monitors[2].all_out[-1][i])\n",
    "                names_to_plot.append(f\"Iteration {i}\")\n",
    "                line_styles.append(\"--\")\n",
    "            prediction_sets.append(monitors[2].final_out[-1])\n",
    "            names_to_plot.append(\"Projected\")\n",
    "            line_styles.append(\"-\")\n",
    "            colors = None\n",
    "            fig = plot_model_predictions(\n",
    "                inputs,\n",
    "                outputs,\n",
    "                prediction_sets,\n",
    "                names_to_plot,\n",
    "                f\"{task_filename}_{model_filename}_projections\",\n",
    "                colors=colors,\n",
    "                line_styles=line_styles,\n",
    "                title=f\"{model_name} Model Predictions\",\n",
    "                directory=save_directory,\n",
    "            )\n",
    "            # Plot predictions over training\n",
    "            num_epochs = len(monitors[2].epoch)\n",
    "            extra_idxs = np.power(1.5, np.arange(num_epochs)).astype(int)\n",
    "            extra_idxs = extra_idxs[extra_idxs < num_epochs]\n",
    "            limited_idxs = np.unique(np.r_[0, extra_idxs, num_epochs - 1])\n",
    "            prediction_sets = list()\n",
    "            names_to_plot = list()\n",
    "            colors = list()\n",
    "            line_styles = list()\n",
    "            for i, idx in enumerate(limited_idxs):\n",
    "                prediction_sets.extend(\n",
    "                    [monitors[2].original_out[idx], monitors[2].final_out[idx]]\n",
    "                )\n",
    "                names_to_plot.extend(\n",
    "                    [f\"Epoch {idx+1} (Unprojected)\", f\"Epoch {idx+1} (Projected)\"]\n",
    "                )\n",
    "                colors.extend([i, i])\n",
    "                line_styles.extend([\":\", \"--\"])\n",
    "            fig = plot_model_predictions(\n",
    "                inputs,\n",
    "                outputs,\n",
    "                prediction_sets,\n",
    "                names_to_plot,\n",
    "                f\"{task_filename}_{model_filename}_predictions\",\n",
    "                colors=colors,\n",
    "                line_styles=line_styles,\n",
    "                title=f\"{model_name} Model Predictions\",\n",
    "                directory=save_directory,\n",
    "            )\n",
    "\n",
    "    else:  # this is probably a checkpoint group for a single run\n",
    "\n",
    "        print(f\"Nothing implemented for {task_name}\")\n",
    "\n",
    "#         fig = plot_constraints_distribution(\n",
    "#             [[monitors[1]] for monitors in task_monitors],\n",
    "#             task_model_names,\n",
    "#             f\"{task_filename}_constraint-distribution\",\n",
    "#             title=\"Distribution of Constraint Residual\",\n",
    "#             ylabel=\"Constraint value\",\n",
    "#             log=False,\n",
    "#             directory=save_directory,\n",
    "#             absolute_value=False,\n",
    "#         )\n",
    "#         fig = plot_constraints_distribution(\n",
    "#             [[monitors[1]] for monitors in task_monitors],\n",
    "#             task_model_names,\n",
    "#             f\"{task_filename}_constraint-distribution-magnitude\",\n",
    "#             title=\"Distribution of Magnitude of Constraint Residual\",\n",
    "#             ylabel=\"Magnitude of constraint value\",\n",
    "#             log=True,\n",
    "#             directory=save_directory,\n",
    "#             absolute_value=True,\n",
    "#         )\n",
    "\n",
    "#         inputs, outputs, predictions = get_model_predictions(task_checkpoints)\n",
    "#         fig = plot_model_predictions(\n",
    "#             inputs,\n",
    "#             outputs,\n",
    "#             predictions,\n",
    "#             task_model_names,\n",
    "#             f\"{task_filename}_predictions\",\n",
    "#             title=\"Model Predictions\",\n",
    "#             directory=save_directory,\n",
    "#         )\n",
    "\n",
    "#     if (\n",
    "#         \"approximation\" in task_filename\n",
    "#         or \"reduction\" in task_filename\n",
    "#         or \"constrained\" in task_filename\n",
    "#     ):\n",
    "\n",
    "#         idxs = np.argsort([checkpoint[\"epoch\"] for checkpoint in task_checkpoints])\n",
    "#         task_checkpoints = np.array(task_checkpoints)[idxs]\n",
    "#         task_model_names = np.array(task_model_names)[idxs]\n",
    "#         task_monitors = np.array(task_monitors)[idxs]\n",
    "\n",
    "#         fig = plot_loss(\n",
    "#             [monitors[1:] for monitors in task_monitors[-1:]],\n",
    "#             [task_name],\n",
    "#             f\"{task_filename}_constrained-loss\",\n",
    "#             title=f\"Total Loss for {task_name}\",\n",
    "#             directory=save_directory,\n",
    "#             constrained=True,\n",
    "#         )\n",
    "#         fig = plot_loss(\n",
    "#             [monitors[1:] for monitors in task_monitors[-1:]],\n",
    "#             [task_name],\n",
    "#             f\"{task_filename}_loss\",\n",
    "#             title=f\"Data Loss for {task_name}\",\n",
    "#             directory=save_directory,\n",
    "#         )\n",
    "#         fig = plot_constraints_distribution(\n",
    "#             [monitors[1:] for monitors in task_monitors[-1:]],\n",
    "#             [task_name],\n",
    "#             f\"{task_filename}_constraint-distribution\",\n",
    "#             title=f\"Distribution of Constraint Residual for {task_name}\",\n",
    "#             ylabel=\"Constraint value\",\n",
    "#             log=False,\n",
    "#             directory=save_directory,\n",
    "#             absolute_value=False,\n",
    "#         )\n",
    "#         fig = plot_constraints_distribution(\n",
    "#             [monitors[1:] for monitors in task_monitors[-1:]],\n",
    "#             [task_name],\n",
    "#             f\"{task_filename}_constraint-distribution-magnitude\",\n",
    "#             title=f\"Distribution of Magnitude of Constraint Residual for {task_name}\",\n",
    "#             ylabel=\"Magnitude of constraint value\",\n",
    "#             log=True,\n",
    "#             directory=save_directory,\n",
    "#             absolute_value=True,\n",
    "#         )\n",
    "#         fig = plot_parameters_distribution(\n",
    "#             [monitors[:1] for monitors in task_monitors[-1:]],\n",
    "#             [task_name],\n",
    "#             f\"{task_filename}_parameter-distribution\",\n",
    "#             title=f\"Distribution of Parameter Values for {task_name}\",\n",
    "#             ylabel=\"Parameter values\",\n",
    "#             log=False,\n",
    "#             directory=save_directory,\n",
    "#             gradients=False,\n",
    "#         )\n",
    "#         fig = plot_parameters_distribution(\n",
    "#             [monitors[:1] for monitors in task_monitors[-1:]],\n",
    "#             [task_name],\n",
    "#             f\"{task_filename}_gradient-distribution\",\n",
    "#             title=f\"Distribution of Parameter Gradients for {task_name}\",\n",
    "#             ylabel=\"Parameter gradients\",\n",
    "#             log=False,\n",
    "#             directory=save_directory,\n",
    "#             gradients=True,\n",
    "#         )\n",
    "\n",
    "#         #         for idx, diagnostic_name in enumerate(\n",
    "#         #             [\"LHS\", \"RHS\", r\"$\\nabla_{\\mathrm{inputs}}(\\mathrm{outputs})$\"]\n",
    "#         #         ):\n",
    "#         #             fig = plot_constraints_diagnostics(\n",
    "#         #                 [monitors[1:] for monitors in task_monitors[-1:]],\n",
    "#         #                 [task_name],\n",
    "#         #                 f\"{task_filename}_constraint-diagnostics{idx}\",\n",
    "#         #                 diagnostics_index=idx,\n",
    "#         #                 title=f\"{task_name} {diagnostic_name}\",\n",
    "#         #                 ylabel=f\"Average {diagnostic_name}\",\n",
    "#         #                 directory=save_directory,\n",
    "#         #             )\n",
    "\n",
    "#         extra_idxs = np.power(1.5, np.arange(len(task_checkpoints))).astype(int)\n",
    "#         extra_idxs = extra_idxs[extra_idxs < len(task_checkpoints)]\n",
    "#         limited_idxs = np.unique(np.r_[0, extra_idxs, len(task_checkpoints) - 1])\n",
    "#         limited_checkpoints = task_checkpoints[limited_idxs]\n",
    "\n",
    "#         inputs, outputs, predictions = get_model_predictions(limited_checkpoints)\n",
    "#         fig = plot_model_predictions(\n",
    "#             inputs,\n",
    "#             outputs,\n",
    "#             predictions,\n",
    "#             [f'Epoch {checkpoint[\"epoch\"]}' for checkpoint in limited_checkpoints],\n",
    "#             f\"{task_filename}_predictions\",\n",
    "#             title=task_name,\n",
    "#             directory=save_directory,\n",
    "#         )\n",
    "\n",
    "# # close all those figures\n",
    "# plt.close(\"all\")"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python [conda env:.conda-torch3]",
   "language": "python",
   "name": "conda-env-.conda-torch3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
