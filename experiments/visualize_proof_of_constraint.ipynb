{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory to the root so that relative path loads work correctly\n",
    "import os\n",
    "\n",
    "try:\n",
    "    os.chdir(os.path.join(os.getcwd(), \"..\"))\n",
    "    print(os.getcwd())\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from experiments.A_proof_of_constraint.main import build_model_and_optimizer, get_data\n",
    "from experiments.A_proof_of_constraint.visualize import (\n",
    "    plot_constraints,\n",
    "    plot_loss,\n",
    "    plot_model_predictions,\n",
    "    plot_time,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_predictions(checkpoints):\n",
    "    # Retrieve the data and equation of the first checkpoint\n",
    "    train_dl, test_dl, parameterization, equation = get_data(\n",
    "        checkpoints[0][\"configuration\"], return_equation=True\n",
    "    )\n",
    "    # Get the models\n",
    "    models = list()\n",
    "    for checkpoint in checkpoints:\n",
    "        model, opt = build_model_and_optimizer(checkpoint[\"configuration\"])\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        models.append(model)\n",
    "    # Get the predictions\n",
    "    inputs = list()\n",
    "    outputs = list()\n",
    "    is_training = list()\n",
    "    predictions = [list() for _ in models]\n",
    "    for xb, yb in train_dl:\n",
    "        inputs.extend(xb.squeeze().detach().numpy())\n",
    "        outputs.extend(yb.squeeze().detach().numpy())\n",
    "        is_training.extend([True for _ in range(len(xb.squeeze()))])\n",
    "        for i, model in enumerate(models):\n",
    "            model.eval()\n",
    "            predictions[i].extend(model(xb).squeeze().detach().numpy())\n",
    "    for xb, yb in test_dl:\n",
    "        inputs.extend(xb.squeeze().detach().numpy())\n",
    "        outputs.extend(yb.squeeze().detach().numpy())\n",
    "        is_training.extend([False for _ in range(len(xb.squeeze()))])\n",
    "        for i, model in enumerate(models):\n",
    "            model.eval()\n",
    "            predictions[i].extend(model(xb).squeeze().detach().numpy())\n",
    "    # sort\n",
    "    idxs = np.argsort(inputs)\n",
    "    inputs = np.array(inputs)[idxs]\n",
    "    outputs = np.array(outputs)[idxs]\n",
    "    is_training = np.array(is_training)[idxs]\n",
    "    predictions = np.array(predictions)[:, idxs]\n",
    "    return (inputs, outputs, is_training), predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files to load\n",
    "experiment_name = \"test\"\n",
    "save_directory = f\"/global/u1/g/gelijerg/Projects/pyinsulate/results/{experiment_name}/\"\n",
    "load_directory = \"/global/u1/g/gelijerg/Projects/pyinsulate/results/checkpoints/\"\n",
    "files_and_names = [\n",
    "    (\"proof-of-constraint_2019-07-31-13-29-01_00002.pth\", \"Average\"),\n",
    "    (\"proof-of-constraint_2019-07-31-13-29-26_00002.pth\", \"Batchwise\"),\n",
    "    (\"proof-of-constraint_2019-07-31-15-27-51_00005.pth\", \"Unconstrained (5)\"),\n",
    "    #     ('proof-of-constraint_2019-07-31-15-27-51_00010.pth', \"Unconstrained (10)\"),\n",
    "    #     ('proof-of-constraint_2019-07-31-15-27-51_00015.pth', \"Unconstrained (15)\"),\n",
    "    #     ('proof-of-constraint_2019-07-31-15-27-51_00020.pth', \"Unconstrained (20)\"),\n",
    "    (\"proof-of-constraint_2019-07-31-15-27-51_00025.pth\", \"Unconstrained (25)\"),\n",
    "    #     ('proof-of-constraint_2019-07-31-15-27-51_00030.pth', \"Unconstrained (30)\"),\n",
    "    #     ('proof-of-constraint_2019-07-31-15-27-51_00035.pth', \"Unconstrained (35)\"),\n",
    "    #     ('proof-of-constraint_2019-07-31-15-27-51_00040.pth', \"Unconstrained (40)\"),\n",
    "    #     ('proof-of-constraint_2019-07-31-15-27-51_00045.pth', \"Unconstrained (45)\"),\n",
    "    (\"proof-of-constraint_2019-07-31-15-27-51_00050.pth\", \"Unconstrained (50)\"),\n",
    "]\n",
    "files = [x[0] for x in files_and_names]\n",
    "model_names = [x[1] for x in files_and_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "checkpoints = [torch.load(f\"{load_directory}/{f}\") for f in files]\n",
    "filenames = [os.path.splitext(f)[0] for f in files]\n",
    "# Make sure directory to save exists\n",
    "os.makedirs(save_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some plotting\n",
    "all_monitors = [checkpoint[\"monitors\"] for checkpoint in checkpoints]\n",
    "training_monitors = [x[0] for x in all_monitors]\n",
    "evalutation_train_monitors = [x[1] for x in all_monitors]\n",
    "evaluation_test_monitors = [x[2] for x in all_monitors]\n",
    "\n",
    "time_keys = [\n",
    "    key\n",
    "    for key in training_monitors[0].time_keys\n",
    "    if (\"multipliers\" in key or \"total\" in key or \"compute\" in key)\n",
    "    and \"error\" not in key\n",
    "]\n",
    "fig = plot_time(\n",
    "    training_monitors,\n",
    "    model_names,\n",
    "    f\"compute-time\",\n",
    "    time_keys=time_keys,\n",
    "    log=True,\n",
    "    directory=save_directory,\n",
    ")\n",
    "\n",
    "\n",
    "fig = plot_loss(\n",
    "    [x[1:] for x in all_monitors],\n",
    "    model_names,\n",
    "    f\"constrained-loss\",\n",
    "    directory=save_directory,\n",
    "    constrained=True,\n",
    ")\n",
    "fig = plot_constraints(\n",
    "    [x[1:] for x in all_monitors], model_names, f\"constraint\", directory=save_directory\n",
    ")\n",
    "fig = plot_loss(\n",
    "    [x[1:] for x in all_monitors], model_names, f\"loss\", directory=save_directory\n",
    ")\n",
    "\n",
    "data, predictions = get_model_predictions(checkpoints)\n",
    "fig = plot_model_predictions(\n",
    "    data, predictions, model_names, f\"predictions\", directory=save_directory\n",
    ")\n",
    "\n",
    "# for checkpoint, filename in zip(checkpoints, filenames):\n",
    "\n",
    "#     training_monitor, evaluation_train_monitor, evaluation_test_monitor = checkpoint[\n",
    "#         \"monitors\"\n",
    "#     ]\n",
    "\n",
    "#     print(checkpoint[\"configuration\"])\n",
    "#     #     print(training_monitor)\n",
    "#     #     print(evaluation_test_monitor.mean_loss)\n",
    "#     plot_loss(\n",
    "#         [evaluation_train_monitor, evaluation_test_monitor],\n",
    "#         [\"Training\", \"Testing\"],\n",
    "#         f\"training-loss_{filename}\",\n",
    "#     )\n",
    "#     plot_loss(\n",
    "#         [evaluation_train_monitor, evaluation_test_monitor],\n",
    "#         [\"Training\", \"Testing\"],\n",
    "#         f\"training-constrained-loss_{filename}\",\n",
    "#         title=\"Constrained losses\",\n",
    "#         constrained=True,\n",
    "#     )\n",
    "#     plot_constraints(\n",
    "#         [evaluation_train_monitor, evaluation_test_monitor],\n",
    "#         [\"Training\", \"Testing\"],\n",
    "#         f\"training-constraint_{filename}\",\n",
    "#     )me}\",\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python [conda env:.conda-torch-gpu]",
   "language": "python",
   "name": "conda-env-.conda-torch-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
